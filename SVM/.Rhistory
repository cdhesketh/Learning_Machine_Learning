n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
n=20000
a=0
b=1
mca = function (n, a, b) {
u = runif(n,a,b)
x = a.2(u)
g = (exp(-x)/(1+x^2))/(exp(-x)/(1-1/exp(1)))
tetahb=mean(g)
tetah_seb=sd(g)/sqrt(n)
list(tetah=tetahb,tetah_se=tetah_seb)
}
mca(n,a,b)
c = runif(n/2,0,1)
u = a.2(c)
gu1 = exp(-u)/(1+u^2)
gu2 = exp(-(1-u))/(1+(1-u)^2)
tetah_c = sum(gu1+gu2)/n
tetaha_c_se = sd(gu1+gu2)/sqrt(n)
print(c(tetah_c,tetaha_c_se))
library(MASS)
hitmiss <- function (n, mu, sigma,a , b, c) {
s=mvrnorm( n, mu, sigma, tol = 1e-6, empirical = FALSE)
tetah = sum(s[,1]<a & s[,2]<b & s[,3]<c)/n # this is the hit-miss approximation to the integral
tetah_se = sqrt((tetah-tetah^2)/n) #This is the standard error of the approimation
return(list(tetah=tetah,tetah_se=tetah_se))
}
n = 20000
a=1; b=4; c=2
mu=c(0,0,0)
sigma = matrix(c(1,3/5,1/3,3/5,1,11/15,1/3,11/15,1),3,3)
I = hitmiss(n, mu, sigma, a, b, c)
I
theta = I$tetah
stdv = I$tetah_se
z = qnorm(.9725,0,1)
lower.bound = theta-z*stdv
upper.bound = theta+z*stdv
print("       Confidence Interval",quote = FALSE)
paste0("(", lower.bound ,",",upper.bound  ,")")
n = 20000
mu = exp(-.5)*atan(1)
x = runif(n,0,1)
g = (1/(1+x^2))*exp(-x)
h = (1/(1+x^2))*exp(-.5)
c.star = -cov(h,g)/var(h)
theta.hat.c = sum(g+c.star*(h-mu))/n
theta.hat.c = mean(g+c.star*(h-mu))
theta.hat.c
sqrt(I.4$tetah_se^2-cor(g,h)^2*I.4$tetah_se^2)
var.cv=(1/n)*(var(g)-(cov(g,h)^2)/var(h))
se.cv=sqrt(var.cv)
se.cv
n = 20000
u = runif(n,0,1)
x=1-sqrt(1-u)
g = (1/(1+x^2))*exp(-x)
h = (1/(1+x^2))*exp(-.5)
f=2*(1-x)
gf=g/f
hf=h/f
mu=exp(-.5)*atan(1)
c.star = -cov(hf,gf)/var(hf)
theta.hat.c = sum(gf+c.star*(hf-mu))/n
theta.hat.c = mean(gf+c.star*(hf-mu))
theta.hat.c
var.cv=(1/n)*(var(gf)-(cov(gf,hf)^2)/var(hf))
se.cv=sqrt(var.cv)
se.cv
help(qtukey)
alpha=.01
qtukey(1-alpha,5,8)
qtukey(1-alpha,5,8)/sqrt(2)
qtukey(1-alpha,5,8)/sqrt(2)
abs(yA-yB)/(sqrt(260))
yA=45
yB=58
yC=46
yD=45
yE=56
abs(yA-yB)/(sqrt(260))
abs(yA-yB)
sqrt(260)
sqrt(260)*2/3
sqrt(260*2/3)
AB=abs(yA-yB)/sqrt(260/124.5)
AB
abs(yA-yB)/sqrt(124.5)
abs(yA-yB)/sqrt(5)
abs(yA-yB)/sqrt(5*2/3)
AB=abs(yA-yB)/sqrt(5*2/3)
AC=abs(yA-yC)/sqrt(5*2/3)
AD=abs(yA-yD)/sqrt(5*2/3)
AE=abs(yA-yE)/sqrt(5*2/3)
BC=abs(yB-yC)/sqrt(5*2/3)
BD=abs(yB-yD)/sqrt(5*2/3)
BE=abs(yB-yE)/sqrt(5*2/3)
CD=abs(yC-yD)/sqrt(5*2/3)
CE=abs(yC-yE)/sqrt(5*2/3)
DE=abs(yD-yE)/sqrt(5*2/3)
AB
AC
AD
AE
alpha=.01
qtukey(1-alpha,5,8)/sqrt(2)
yA=45
yB=58
yC=46
yD=45
yE=56
AB=abs(yA-yB)/sqrt(5*2/3)
AC=abs(yA-yC)/sqrt(5*2/3)
AD=abs(yA-yD)/sqrt(5*2/3)
AE=abs(yA-yE)/sqrt(5*2/3)
BC=abs(yB-yC)/sqrt(5*2/3)
BD=abs(yB-yD)/sqrt(5*2/3)
BE=abs(yB-yE)/sqrt(5*2/3)
CD=abs(yC-yD)/sqrt(5*2/3)
CE=abs(yC-yE)/sqrt(5*2/3)
DE=abs(yD-yE)/sqrt(5*2/3)
AB
AC
AD
AE
BC
BD
BE
CD
CE
DE
AB
AC
AD
AE
BC
BD
BE
CD
CE
DE
help(tstats)
qtukey(1-alpha,5,8)/sqrt(2)
data=cbind(c(9,19,28,22,18,8),c(10,22,30,21,23,12))
data
data <- read.table("http://www2.isye.gatech.edu/%7Ejeffwu/book/data/girder.dat", h=T)
y <- c(t(data))
y
data
data=c(9,19,28,22,18,8,10,22,30,21,23,12)
data
data=c(9,19,28,22,18,8,10,22,30,21,23,12)
data
girder=rep(1:6, rep(4,9))
method=rep(1:2, 6)
cbind(data, method, y)
data=c(9,19,28,22,18,8,10,22,30,21,23,12)
data
girder=rep(1:6, rep(4,9))
method=rep(1:2, 6)
cbind(data, method, y)
cbind(girder, method, data)
data=c(9,19,28,22,18,8,10,22,30,21,23,12)
data
girder=rep(1:6, rep(4,9))
method=rep(1:2, 6)
cbind(girder, method, data)
rep(1:6, rep(4,9))
ep(1:9, rep(4,9))
rep(1:9, rep(4,9))
rep(4,9)
rep(1:6, 6)
girder=rep(1:6, rep(2,6))
girder
rep(1:6, rep(6,2))
rep(1:2, 6)
rep(1:9, rep(4,9))
rep(1:4, 9)
method=rep(1:6, 2)
method
data=c(9,19,28,22,18,8,10,22,30,21,23,12)
data
num=c(1,1,1,1,1,1,2,2,2,2,2,2)
method=rep(1:6, 2)
cbind(num, method, data)
data=c(9,19,28,22,18,8,10,22,30,21,23,12)
data
cat=c(1,1,1,1,1,1,2,2,2,2,2,2)
method=rep(1:6, 2)
cbind(cat, method, data)
g <- lm(data~as.factor(cat)+as.factor(method))
anova(g)
data=c(9,19,28,22,18,8,10,22,30,21,23,12)
data
cat=c(1,1,1,1,1,1,2,2,2,2,2,2)
batch=rep(1:6, 2)
cbind(cat, batch, data)
g <- lm(data~as.factor(cat)+as.factor(batch))
anova(g)
t.test(data[1:6],data[7,12],paired = T,alternative="two.sided")
data[7,12]
data
data[7,11]
t.test(data[1:6],data[7:12],paired = T,alternative="two.sided")
anova(g)
t.test(data[1:6],data[7:12],paired = T,alternative="two.sided")
data[7:12],
t.test(data[7:12],data[1:6],paired = T,alternative="two.sided")
data=c(9,19,28,22,18,8,10,22,30,21,23,12)
data
t.test(data[1:6],data[7:12],paired = T,alternative="two.sided")
data=read.table("https://www2.isye.gatech.edu/~jeffwu/book/data/throughput.dat", h=T)
data
data <- read.table("http://www2.isye.gatech.edu/~jeffwu/book/data/wear.dat", h=T)
data
g <- lm(wear ~ as.factor(row) + as.factor(col) + material, data = data)
anova(g)
summary(g)
g <- lm(wear ~ material, data = data) #ignoring blocking
anova(g)
data=read.table("https://www2.isye.gatech.edu/~jeffwu/book/data/throughput.dat", h=T)
data
data <- read.table("http://www2.isye.gatech.edu/~jeffwu/book/data/wear.dat", h=T)
data
g <- lm(Throughput ~ as.factor(Day) + as.factor(Operator)+ as.factor(Machine)+ as.factor(Method), data = data)
data=read.table("https://www2.isye.gatech.edu/~jeffwu/book/data/throughput.dat", h=T)
data
g <- lm(Throughput ~ as.factor(Day) + as.factor(Operator)+ as.factor(Machine)+ as.factor(Method), data = data)
anova(g)
results=aov(g)
results
results=aov(formula = Throughput ~ as.factor(Day) + as.factor(Operator)+ as.factor(Machine)+ as.factor(Method), data = data)
results
library(DescTools)
install.packages("DescTools")
library(DescTools)
results
aov(formula = Throughput ~ as.factor(Day) + as.factor(Operator)+ as.factor(Machine)+ as.factor(Method), data = data)
summary(results)
PostHocTest(results,method="Tukey")$Method
PostHocTest(results,method="bonferroni")$Method
PostHocTest(results,method="bonferroni")
PostHocTest(results,method="bonferroni")$as.factor(Method)
PostHocTest(results,method="bonferroni")$'as.factor(Method)'
help("PostHocTest")
data=cbind(c(1,-1,1,-1,1,-1,1,-1),c(-1,-1,1,1,-1,-1,1,1),c(-1,-1,-1,-1,1,1,1,1))
y=cbind(c(11,12,10,11,16,14,15,19))
flasherType = data[,1]
inertia = data[,2]
task = data[,3]
g = lm(y~flasherType*inertia*task) #location effect model
summary(g)
sqrt(3.25)+sqrt(2.5)
library(reshape2)
library(DescTools)
library(ggplot2)
library(FrF2)
library(BsMD)
#####################################
#1)
#####################################
#2 a)
data=cbind(c(1,-1,1,-1,1,-1,1,-1),c(-1,-1,1,1,-1,-1,1,1),c(-1,-1,-1,-1,1,1,1,1))
y=cbind(c(11,12,10,11,16,14,15,19))
flasherType = data[,1]
inertia = data[,2]
task = data[,3]
g = lm(y~flasherType*inertia*task) #location effect model
summary(g)
#b
#full log, not useful just for completeness
DanielPlot(g, half=F, autolab=F, main="Normal plot of location effects")
#half log, shows flash:inert:task,Flash:inertia,task are off the normal line/not grouped together
DanielPlot(g, half=T, autolab=F, main="Normal plot of location effects")
library(reshape2)
library(DescTools)
library(ggplot2)
library(FrF2)
library(BsMD)
#####################################
#1)
#####################################
#2 a)
data=cbind(c(1,-1,1,-1,1,-1,1,-1),c(-1,-1,1,1,-1,-1,1,1),c(-1,-1,-1,-1,1,1,1,1))
y=cbind(c(11,12,10,11,16,14,15,19))
flasherType = data[,1]
inertia = data[,2]
task = data[,3]
g = lm(y~flasherType*inertia*task) #location effect model
summary(g)
#b
#full log, not useful just for completeness
DanielPlot(g, half=F, autolab=F, main="Normal plot of location effects")
#half log, shows flash:inert:task,Flash:inertia,task are off the normal line/not grouped together
DanielPlot(g, half=T, autolab=F, main="Normal plot of location effects")
effect = round(2*g$coef[-1],3)
effect
median(abs(effect))
s0 = 1.5*median(abs(effect))
s0
2.5*s0
abs(effect)<2.5*s0
PSE = 1.5*median(abs(effect[abs(effect)<2.5*s0]))
PSE
tPSE=abs(effect)/PSE
#let alpha be 0.01, then IER of alpha is 5.07
abs(tPSE)>5.07
#let alpha be 0.01, then IER of alpha is 5.07
abs(tPSE)
library(ISLR)
library(MASS)
library(glmnet)
library(assist)
library(pls)
library(gplots)
library(class)
library(e1071)
library(caret)
library(rpart)
library(randomForest)
library(gridExtra)
setwd("C:\\Users\\User\\Desktop\\School\\Current_Semester\\Math_533\\Midterm")
#read data in
adult <- read.csv('adult.data',
sep = ',', fill = F, strip.white = T, stringsAsFactors=T)
colnames(adult) <- c('age', 'workclass', 'fnlwgt', 'education',
'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex',
'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income')
head(adult)
rawRow=nrow(adult)
#replace ? with na to remove them
adult[adult=="?"]=NA
adult=na.omit(adult)
noNARow=nrow(adult)
#Find the columns that are too spread out across different catagories
#drop 3,11,12,13,14
for(i in 1:length(adult))
{
print(paste(i,": ",length(unique(adult[,i]))))
}
#remove the columns that will cause issues
adult=adult[,-c(14)]
#quick check to see if there are any columns that would not be significant based on a
# generalized linear model
model = glm(income~.,data=adult,family=binomial(link="logit"))
summary(model)
adult[,4:5]
#Can drop education_num
adult=adult[,-c(5)]
#Plot Catagorical Data
plot1=ggplot(adult)+geom_bar(aes(x=workclass))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot2=ggplot(adult)+geom_bar(aes(x=education))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot3=ggplot(adult)+geom_bar(aes(x=marital_status))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot4=ggplot(adult)+geom_bar(aes(x=occupation)) +theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot5=ggplot(adult)+geom_bar(aes(x=relationship))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot6=ggplot(adult)+geom_bar(aes(x=race))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot7=ggplot(adult)+geom_bar(aes(x=sex))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
grid.arrange(plot1,plot2,plot3,plot4, ncol=2)
grid.arrange(plot5,plot6,plot7, ncol=2)
#Plot Continuous Data
plot8=ggplot(adult)+geom_histogram(aes(x=fnlwgt))
plot9=ggplot(adult)+geom_histogram(aes(x=age))
plot10=ggplot(adult)+geom_histogram(aes(x=capital_gain))
plot11=ggplot(adult)+geom_histogram(aes(x=capital_loss))
plot12=ggplot(adult)+geom_histogram(aes(x=hours_per_week))
grid.arrange(plot8,plot9,plot10, ncol=2)
grid.arrange(plot11,plot12, ncol=2)
#Plot response variable
ggplot(adult)+geom_bar(aes(x=income))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
#set up test and train data with 20% in test
testIndexes=sample(1:nrow(adult),size=nrow(adult)*.2)
testData=adult[testIndexes,]
trainData=adult[-testIndexes,]
tuneRND=sample(dim(trainData),1000)
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(-5,5),gamma=10^c(-5,1)))
tunout
trainData
sample(dim(trainData),1000)
dim(trainData)
tuneRND=sample(dim(trainData)[1],1000)
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(-5,5),gamma=10^c(-5,1)))
tunout
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(5,10),gamma=10^c(-10,-5)))
tunout
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(10,15),gamma=(10^(-5)+c(-1000:0))))
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(10,15),gamma=10^(-5)))
tunout
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(15,35),gamma=10^(-5)))
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(15,25),gamma=10^(-5)))
tunout
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(15,20),gamma=10^(-5)))
tunout
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^15,gamma=10^c(-5,-10)))
tunout
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^15,gamma=10^c(-5,-7)))
tunout
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^15,gamma=10^c(-5,-6)))
tunout
modelSVM=svm(income~.,data=trainData,cost=10^15,gamma=10^(-5))
#Predict SVM and Confusion Matrix
predSVM=predict(modelSVM,testData)
confusionMatrix(testData$income,predSVM)
modelSVM=svm(income~.,data=trainData)
#Predict SVM and Confusion Matrix
predSVM=predict(modelSVM,testData)
confusionMatrix(testData$income,predSVM)
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(12,17),gamma=10^c(-5,-6)))
tunout
library(ISLR)
library(MASS)
library(glmnet)
library(assist)
library(pls)
library(gplots)
library(class)
library(e1071)
library(caret)
library(rpart)
library(randomForest)
library(gridExtra)
setwd("C:\\Users\\User\\Desktop\\School\\Current_Semester\\Math_533\\Midterm")
#read data in
adult <- read.csv('adult.data',
sep = ',', fill = F, strip.white = T, stringsAsFactors=T)
colnames(adult) <- c('age', 'workclass', 'fnlwgt', 'education',
'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex',
'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income')
head(adult)
rawRow=nrow(adult)
#replace ? with na to remove them
adult[adult=="?"]=NA
adult=na.omit(adult)
noNARow=nrow(adult)
#Find the columns that are too spread out across different catagories
#drop 3,11,12,13,14
for(i in 1:length(adult))
{
print(paste(i,": ",length(unique(adult[,i]))))
}
#remove the columns that will cause issues
adult=adult[,-c(14)]
#quick check to see if there are any columns that would not be significant based on a
# generalized linear model
model = glm(income~.,data=adult,family=binomial(link="logit"))
summary(model)
adult[,4:5]
#Can drop education_num
adult=adult[,-c(5)]
#Plot Catagorical Data
plot1=ggplot(adult)+geom_bar(aes(x=workclass))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot2=ggplot(adult)+geom_bar(aes(x=education))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot3=ggplot(adult)+geom_bar(aes(x=marital_status))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot4=ggplot(adult)+geom_bar(aes(x=occupation)) +theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot5=ggplot(adult)+geom_bar(aes(x=relationship))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot6=ggplot(adult)+geom_bar(aes(x=race))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
plot7=ggplot(adult)+geom_bar(aes(x=sex))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
grid.arrange(plot1,plot2,plot3,plot4, ncol=2)
grid.arrange(plot5,plot6,plot7, ncol=2)
#Plot Continuous Data
plot8=ggplot(adult)+geom_histogram(aes(x=fnlwgt))
plot9=ggplot(adult)+geom_histogram(aes(x=age))
plot10=ggplot(adult)+geom_histogram(aes(x=capital_gain))
plot11=ggplot(adult)+geom_histogram(aes(x=capital_loss))
plot12=ggplot(adult)+geom_histogram(aes(x=hours_per_week))
grid.arrange(plot8,plot9,plot10, ncol=2)
grid.arrange(plot11,plot12, ncol=2)
#Plot response variable
ggplot(adult)+geom_bar(aes(x=income))+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
#set up test and train data with 20% in test
testIndexes=sample(1:nrow(adult),size=nrow(adult)*.2)
testData=adult[testIndexes,]
trainData=adult[-testIndexes,]
tuneRND=sample(dim(trainData)[1],1000)
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(12,17),gamma=10^c(-5,-6)))
tunout
tunout=tune(svm,income~.,data=trainData[tuneRND,],kernel="radial",range=list(cost=10^c(12,17),gamma=10^c(-2,1)))
tunout
